---
title: "Random Forest Examples"
author: "Bastola"
date: "`r format(Sys.Date(), ' %B %d %Y')`"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      collapse = TRUE, 
                      comment=NA, 
                      warning = FALSE,
                      message = FALSE,
                      fig.height = 4, fig.width = 6, fig.align='center')
                      

library(tidyverse) 
library(tidymodels)
library(mlbench)     # for PimaIndiansDiabetes2 dataset
library(parsnip)
library(ISLR)
library(rpart.plot)
library(vip)
library(janitor)

fire <- read_csv("https://raw.githubusercontent.com/deepbas/statdatasets/main/Algeriafires.csv")
fire <- fire %>% clean_names() %>% 
  na.omit() %>% 
  mutate_at(c(10,13), as.numeric) %>%
  mutate(classes = as.factor(classes)) %>%
  select(-year, -day, -month)
```

# Your turn 1

Use the `fire` data set and predict fire using all available predictor variables.

a. Split the dataset into training and test set by the proportion $90$ to $10$, create a 10 fold cross validation object, and a recipe tp preprocess the data.


```{r}
set.seed(314) # Remember to always set your seed. Any integer will work

fire_split <- initial_split(fire, prop = , 
                             strata = )

fire_train <-
fire_test <- 

# Create folds for cross validation on the training data set

fire_folds <- vfold_cv(, v = , strata = )

fire_recipe <- recipe(classes ~ ., data = ) %>%
 step_dummy(all_nominal(), -all_outcomes()) %>%
 prep()

```


b. Specify a decision tree classification model with `rpart` computational engine. Prepare the model for tuning (i.e., fitting with a range of parameters for validation purposes).

```{r}
tree_model <- decision_tree(cost_complexity = ,
                            tree_depth = ,
                            min_n = ) %>% 
              set_engine('rpart') %>% 
              set_mode('classification')
```

c. Combine the model and recipe into a workflow to easily manage the model-building process.

```{r}
tree_workflow <- workflow() %>% 
                 add_model() %>% 
                 add_recipe()
```

d. Create a grid of hyper-parameter values to test

```{r}
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          min_n(), 
                          levels = 2)
```

e. Tune decision tree workflow

```{r}
set.seed(314)
tree_tuning <- tree_workflow %>% 
               tune_grid(resamples = ,
                         grid = )
```


f. Show the best models under the ROC-AUC criteria.

```{r}
tree_tuning %>% show_best('roc_auc')
```

g. Select best model based on roc_auc and view the best parameters. What is the corresponding tree depth?

```{r}
best_tree <- tree_tuning %>% 
             select_best(metric = 'roc_auc')
best_tree
```


h. Using the `best_tree` object, finalize the workflow using `finalize_workflow()`. 

```{r}
final_tree_workflow <- tree_workflow %>% 
                       finalize_workflow()
```

i. Fit the train data to using the finalized workflow and extract the fit.

```{r}
tree_wf_fit <- final_tree_workflow %>% 
               fit(data = )
```


```{r}
tree_fit <- tree_wf_fit %>% 
            extract_fit_parsnip()
```

j. Construct variable importance plot. What can you conclude from this plot?

```{r}
vip(tree_fit)
```

k. Construct a decision tree. What do you see in this plot?

```{r}
rpart.plot(tree_fit$fit, roundint = FALSE)
```

-----------------------------------------------------------------

# Your turn 2

Use the `fire` dataset again to fit a random forest algorithm to produce optimal set of variables used in predicting fire. Use the same recipe defined earlier in your turn 1.

a. Specify a decision tree classification model with `ranger` computational engine and `impurity` for variable importance. Prepare the model for tuning (i.e., fitting with a range of parameters for validation purposes).


```{r}
rf_model <- rand_forest(mtry = ,
                        trees = ,
                        min_n = %>% 
            set_engine('ranger', importance = "impurity") %>% 
            set_mode('classification')
```

b. Define a workflow object.

```{r}
rf_workflow <- workflow() %>% 
               add_model() %>% 
               add_recipe()
```

c. Create a grid of hyperparameter values to test. Try different values.

```{r}
rf_grid <- grid_random(mtry() %>% range_set(c(1, 8)),
                       trees(),
                       min_n(),
                       size = 10)
```


d. Tune the random forest workflow. Use the `fire_folds` object from before with 10 cross validation routine.

```{r}
rf_tuning <- rf_workflow %>% 
             tune_grid(resamples = ,
                       grid = )
```

e. Select the best model based on ROC-AUC.


```{r}
best_rf <- rf_tuning %>% 
           select_best(metric = 'roc_auc')
```


f. Finalize the workflow, fit the model, and extract the parameters.

```{r}
final_rf_workflow <- rf_workflow %>% 
                     finalize_workflow()
rf_wf_fit <- final_rf_workflow %>% 
             fit(data = )
rf_fit <- rf_wf_fit %>% 
          extract_fit_parsnip()
```

g. Plot the variable importance. What can you conclude from this plot?


```{r}
vip(rf_fit)
```



